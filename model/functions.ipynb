{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "#%pip install --quiet yfinance yahooquery\n",
    "import re\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from yahooquery import search\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data cleaning function for faulty lines\n",
    "def merge_faulty_rows(df):\n",
    "    # Merge rows where file has split data across multiple rows\n",
    "    new_df = df.copy().astype(object)\n",
    "    new_df[\"Date\"] = new_df[\"Date\"].replace(\"\", pd.NA)\n",
    "    bad_date_mask = new_df[\"Date\"].isna()\n",
    "    to_drop = []\n",
    "    for idx in new_df.index[bad_date_mask]:\n",
    "        prev_idx = idx - 1\n",
    "        if prev_idx < 0:\n",
    "            continue\n",
    "        for col in new_df.columns:\n",
    "            val_bad = new_df.at[idx, col]\n",
    "            if pd.notna(val_bad) and str(val_bad).strip() != \"\":\n",
    "                prev_val = new_df.at[prev_idx, col]\n",
    "                if pd.notna(prev_val) and str(prev_val).strip() != \"\":\n",
    "                    new_df.at[prev_idx, col] = f\"{prev_val}{val_bad}\"\n",
    "                else:\n",
    "                    new_df.at[prev_idx, col] = val_bad\n",
    "        to_drop.append(idx)\n",
    "    new_df = new_df.drop(index=to_drop).reset_index(drop=True)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get running cash balance\n",
    "def get_cash_balance(data) -> pd.DataFrame:\n",
    "    # Get final balance on each transaction day\n",
    "    balance_tr = data.iloc[:, [0, -2]]\n",
    "    balance_tr.columns = ['Date', 'Position_EUR']\n",
    "    balance_tr['Date'] = pd.to_datetime(balance_tr['Date'], format='%d-%m-%Y')\n",
    "    balance_tr = balance_tr.groupby(balance_tr.columns[0], as_index=False).first()\n",
    "\n",
    "    # Fill in missing dates with previous balance\n",
    "    start_date = balance_tr.loc[balance_tr['Position_EUR']>0, 'Date'].min()\n",
    "    current_day = pd.to_datetime('today')\n",
    "    date_range = pd.date_range(start=start_date, end=current_day, freq='D')\n",
    "    df_dates = pd.DataFrame({'Date': date_range})\n",
    "    daily_balance = pd.merge(df_dates, balance_tr, on='Date', how='left')\n",
    "    daily_balance = daily_balance.sort_values(by='Date').reset_index(drop=True)\n",
    "    daily_balance = daily_balance.fillna(method='ffill')\n",
    "    daily_balance['Ticker'] = 'CASH'\n",
    "    return daily_balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_quantity(text):\n",
    "    # Remove rights issues prefix when applicable\n",
    "    text = text.split(': ')[-1]\n",
    "\n",
    "    # Split by spaces\n",
    "    tokens = text.split()\n",
    "    if tokens[0] in [\"Compra\", \"Venda\"]:\n",
    "        # Check if the second token is numeric after cleaning\n",
    "        first_num = tokens[1].replace(\".\", \"\").replace(\",\", \"\")\n",
    "        \n",
    "        # Try to see if there's a second number that should be combined\n",
    "        if len(tokens) > 2 and tokens[2][0].isdigit():\n",
    "            # If the next token starts with a digit, combine them\n",
    "            second_num = tokens[2].replace(\".\", \"\").replace(\",\", \"\")\n",
    "            qty_str = first_num + second_num\n",
    "        else:\n",
    "            # If not, just use the first number\n",
    "            qty_str = first_num\n",
    "            \n",
    "        return int(qty_str)\n",
    "    return None\n",
    "\n",
    "\n",
    "def extract_price(text):\n",
    "    match = re.search(r'@([\\d\\s]+(?:,\\d+)?)', text)\n",
    "    if not match:\n",
    "        raise ValueError(f\"No valid amount found in the string: {text}\")\n",
    "    \n",
    "    num_str = match.group(1)\n",
    "    num_str = re.sub(r'\\s+', '', num_str)  # remove all whitespace\n",
    "    num_str = num_str.replace(',', '.')    # turn comma into decimal point\n",
    "    currency = text.split()[-2]\n",
    "    return float(num_str), currency\n",
    "\n",
    "\n",
    "def load_trades(data) -> pd.DataFrame:\n",
    "    # Ensure correct number of columns exist\n",
    "    if data.shape[1] != 12:\n",
    "        raise ValueError(f\"Number of columns in table does not match statement structure.\")\n",
    "\n",
    "    # Keep only relevant rows\n",
    "    trades = data.iloc[:, [0,4,5,8]].copy()\n",
    "    trades = trades.loc[~data['ISIN'].isna()]\n",
    "    trades.columns = ['Date','ISIN','Transaction','Amount']\n",
    "    trades = trades[trades.apply(lambda row: row['Transaction'].endswith(\"(\" + row['ISIN'] + \")\"), axis=1)]\n",
    "\n",
    "    parsed_rows = []\n",
    "    for _, row in trades.iterrows():\n",
    "        tr = row[\"Transaction\"]\n",
    "        isin_raw = row[\"ISIN\"]\n",
    "        isin = isin_raw.strip().upper()\n",
    "\n",
    "        # Skip invalid-format ISIN immediately\n",
    "        ISIN_PATTERN = re.compile(r\"^[A-Z]{2}[A-Z0-9]{9}[0-9]$\")\n",
    "        if not ISIN_PATTERN.match(isin):\n",
    "            continue\n",
    "\n",
    "        # Parse date into pandas.Timestamp\n",
    "        raw_date = row[\"Date\"].strip()\n",
    "        dt_py = datetime.strptime(raw_date, \"%d-%m-%Y\").date()\n",
    "        dt = pd.Timestamp(dt_py)\n",
    "\n",
    "        # Quantity is the second token; remove spaces (thousands separator) and other separators\n",
    "        qty_str = extract_quantity(tr)\n",
    "        try:\n",
    "            qty = int(qty_str)\n",
    "        except ValueError:\n",
    "            continue\n",
    "        side = tr.replace('Compra','Buy').replace('Venda','Sell')  \n",
    "        qty = qty if \"Buy\" in side else -qty\n",
    "\n",
    "        # After \"@\", we have \"<price> <CURRENCY> (<ISIN>)\"\n",
    "        price_local, currency = extract_price(tr)\n",
    "\n",
    "        parsed_rows.append({\n",
    "            \"Date\": dt,\n",
    "            \"ISIN\": isin,\n",
    "            \"Qty\": qty,\n",
    "            \"Currency\": currency,\n",
    "            \"Price\": price_local\n",
    "        })\n",
    "\n",
    "    parsed = pd.DataFrame(parsed_rows)\n",
    "    return parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_isin_to_ticker(isin: str) -> str | None:\n",
    "    \"\"\"\n",
    "    Use yahooquery.search(isin) to fetch the top quote's \"symbol\".\n",
    "    Returns the ticker if found, else None.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        resp = search(isin)\n",
    "    except Exception:\n",
    "        return None\n",
    "    if not isinstance(resp, dict):\n",
    "        return None\n",
    "    quotes = resp.get(\"quotes\", [])\n",
    "    if not quotes:\n",
    "        return None\n",
    "    return quotes[0].get(\"symbol\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_positions(parsed: pd.DataFrame, all_isins: set[str]) -> pd.DataFrame:\n",
    "    filtered = parsed[parsed[\"ISIN\"].isin(all_isins)].copy()\n",
    "    if filtered.empty:\n",
    "        return pd.DataFrame(columns=[\"Date\", \"ISIN\", \"Qty_cum\", \"Currency\"])\n",
    "\n",
    "    grouped = filtered.groupby([\"ISIN\", \"Date\", \"Currency\"], as_index=False).agg({\"Qty\": \"sum\"})\n",
    "    if grouped.empty:\n",
    "        return pd.DataFrame(columns=[\"Date\", \"ISIN\", \"Qty_cum\", \"Currency\"])\n",
    "\n",
    "    first_date = grouped[\"Date\"].min()\n",
    "    last_date = grouped[\"Date\"].max()\n",
    "    all_days = pd.DataFrame({\"Date\": pd.bdate_range(first_date, last_date)})\n",
    "\n",
    "    dfs = []\n",
    "    for isin, sub in grouped.groupby(\"ISIN\"):\n",
    "        curr = sub[\"Currency\"].iloc[0]\n",
    "        temp = all_days.copy()\n",
    "        temp[\"ISIN\"] = isin\n",
    "        temp = temp.merge(sub[[\"Date\", \"Qty\"]], on=\"Date\", how=\"left\").sort_values(\"Date\")\n",
    "        temp[\"Qty\"] = temp[\"Qty\"].fillna(0).astype(int)\n",
    "        temp[\"Qty_cum\"] = temp[\"Qty\"].cumsum()\n",
    "        temp[\"Currency\"] = curr\n",
    "\n",
    "        nz_idx = temp.index[temp[\"Qty_cum\"] != 0]\n",
    "        if len(nz_idx) == 0:\n",
    "            continue\n",
    "        first_nz = temp.loc[nz_idx[0], \"Date\"]\n",
    "        temp = temp[temp[\"Date\"] >= first_nz].copy()\n",
    "        temp = temp[temp[\"Qty_cum\"] != 0].copy()\n",
    "        dfs.append(temp)\n",
    "\n",
    "    if not dfs:\n",
    "        return pd.DataFrame(columns=[\"Date\", \"ISIN\", \"Qty_cum\", \"Currency\"])\n",
    "\n",
    "    return pd.concat(dfs, axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(csv_path: str | None = None):\n",
    "    # 1) Load trades from CSV\n",
    "    data = pd.read_csv(csv_path).pipe(merge_faulty_rows)\n",
    "    parsed = load_trades(data)\n",
    "    if parsed.empty:\n",
    "        print(\"No valid trades found. Exiting.\")\n",
    "        return\n",
    "\n",
    "    # 2) Map each unique ISIN to ticker (via yahooquery); collect unmapped\n",
    "    unique_isins = set(parsed[\"ISIN\"].unique().tolist())\n",
    "    isin_to_ticker: dict[str, str] = {}\n",
    "    not_mapped: set[str] = set()\n",
    "    print(\"\\n2) Mapping ISINs → Yahoo tickers:\")\n",
    "    for isin in sorted(unique_isins):\n",
    "        ticker = map_isin_to_ticker(isin)\n",
    "        if ticker:\n",
    "            isin_to_ticker[isin] = ticker\n",
    "            print(f\"  ✔ {isin} → {ticker}\")\n",
    "        else:\n",
    "            not_mapped.add(isin)\n",
    "            print(f\"  ✘ {isin} → NOT FOUND\")\n",
    "\n",
    "    # 3) Build end‐of‐day positions for all ISINs (mapped + unmapped)\n",
    "    positions = build_positions(parsed, unique_isins)\n",
    "    if positions.empty:\n",
    "        return\n",
    "    # Attach ticker (NaN for unmapped)\n",
    "    positions[\"Ticker\"] = positions[\"ISIN\"].map(isin_to_ticker)\n",
    "    # positions = positions[positions[\"ISIN\"].isin(['ES0183746314','DE0007500001'])]\n",
    "\n",
    "    # 4) Build price_map for unmapped ISINs\n",
    "    price_map = {}\n",
    "    for isin in not_mapped:\n",
    "        sub = parsed[parsed[\"ISIN\"] == isin].sort_values(\"Date\")\n",
    "        if sub.empty:\n",
    "            continue\n",
    "        purchases = sub[sub[\"Qty\"] > 0]\n",
    "        if not purchases.empty:\n",
    "            price_map[isin] = purchases.iloc[0][\"Price\"]\n",
    "        else:\n",
    "            price_map[isin] = sub.iloc[0][\"Price\"]\n",
    "\n",
    "    # 5) Download historical close prices for *mapped* tickers via yfinance\n",
    "    first_date = positions[\"Date\"].min()\n",
    "    last_date = positions[\"Date\"].max()\n",
    "    yf_start = first_date.strftime(\"%Y-%m-%d\")\n",
    "    yf_end = (last_date + timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "    unique_tickers = list(isin_to_ticker.values())\n",
    "\n",
    "    if unique_tickers:\n",
    "        yf_data = yf.download(\n",
    "            tickers=unique_tickers,\n",
    "            start=yf_start,\n",
    "            end=yf_end,\n",
    "            progress=False\n",
    "        )\n",
    "        close_df = yf_data[\"Close\"].copy()\n",
    "        all_bdays = pd.bdate_range(first_date, last_date)\n",
    "        close_df = close_df.reindex(all_bdays).ffill()\n",
    "    else:\n",
    "        all_bdays = pd.bdate_range(first_date, last_date)\n",
    "        close_df = pd.DataFrame(index=all_bdays)\n",
    "\n",
    "    # 6) Download FX rates for non‐EUR positions\n",
    "    currencies = positions[\"Currency\"].unique().tolist()\n",
    "    fx_tickers = [f\"EUR{c}=X\" for c in currencies if c != \"EUR\"]\n",
    "    if fx_tickers:\n",
    "        fx_data = yf.download(\n",
    "            tickers=fx_tickers,\n",
    "            start=yf_start,\n",
    "            end=yf_end,\n",
    "            progress=False\n",
    "        )\n",
    "        fx_close = fx_data[\"Close\"].copy()\n",
    "        fx_close = fx_close.reindex(all_bdays).ffill()\n",
    "    else:\n",
    "        fx_close = pd.DataFrame(index=all_bdays)\n",
    "\n",
    "    # 7) Merge positions with prices & FX (use price_map for unmapped)\n",
    "    def get_close_local(row):\n",
    "        isin = row[\"ISIN\"]\n",
    "        if isin in price_map:\n",
    "            close = float(price_map[isin])\n",
    "            return round(close, 3)\n",
    "        close = float(close_df.loc[row[\"Date\"], row[\"Ticker\"]])\n",
    "        return round(close, 3)\n",
    "\n",
    "    def get_fx_rate(row):\n",
    "        if row[\"Currency\"] == \"EUR\":\n",
    "            return 1.0\n",
    "        fx_sym = f\"EUR{row['Currency']}=X\"\n",
    "        return float(fx_close.loc[row[\"Date\"], fx_sym])\n",
    "\n",
    "    positions[\"Close_Local\"] = positions.apply(get_close_local, axis=1)\n",
    "    positions[\"FX_Rate\"]    = positions.apply(get_fx_rate, axis=1)\n",
    "    positions[\"Close_EUR\"]  = positions[\"Close_Local\"] / positions[\"FX_Rate\"]\n",
    "    positions[\"Position_EUR\"] = positions[\"Qty_cum\"] * positions[\"Close_EUR\"]\n",
    "    positions = positions[positions['Position_EUR']>0]\n",
    "\n",
    "    # 8) Load & build daily EUR cash balance\n",
    "    cash = get_cash_balance(data)  \n",
    "    cash = cash.loc[cash['Date'].isin(all_bdays.tolist())]\n",
    "    positions = pd.concat([positions, cash]).sort_values(by='Date').reset_index(drop=True)\n",
    "\n",
    "    # 10) Final DataFrame and save\n",
    "    output_filename = \"daily_positions_eur_notional_with_cash.csv\"\n",
    "    positions.to_csv(output_filename, index=False)\n",
    "\n",
    "    return positions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Account.csv file\n",
    "df = pd.read_csv('../Account.csv')\n",
    "\n",
    "# Get running cash balance\n",
    "cash = get_cash_balance(df)\n",
    "\n",
    "# Get all trades\n",
    "trades = load_trades(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2) Mapping ISINs → Yahoo tickers:\n",
      "  ✔ DE0007500001 → TKA.DE\n",
      "  ✔ DE000A161408 → HFG.DE\n",
      "  ✔ ES0110047919 → OLE.MC\n",
      "  ✔ ES0127797019 → EDPR.LS\n",
      "  ✘ ES0183746108 → NOT FOUND\n",
      "  ✔ ES0183746314 → VID.MC\n",
      "  ✘ ES06837469A4 → NOT FOUND\n",
      "  ✘ ES06837469B2 → NOT FOUND\n",
      "  ✘ ES06837469C0 → NOT FOUND\n",
      "  ✔ FR0000054470 → UBI.PA\n",
      "  ✔ FR0013447729 → VRLA.PA\n",
      "  ✔ JP3481200008 → 3350.T\n",
      "  ✔ KYG6683N1034 → NU\n",
      "  ✔ LU1598757687 → MT.AS\n",
      "  ✔ NL0010273215 → ASML.AS\n",
      "  ✔ PLMOBRK00013 → MBR.WA\n",
      "  ✔ PLOPTTC00011 → CDR.WA\n",
      "  ✔ PTALT0AE0002 → ALTR.LS\n",
      "  ✔ PTBCP0AM0015 → BCP.LS\n",
      "  ✘ PTCFN0AE0003 → NOT FOUND\n",
      "  ✔ PTCOR0AE0006 → COR.LS\n",
      "  ✔ PTGAL0AM0009 → GALP.LS\n",
      "  ✘ PTGNV0AM0001 → NOT FOUND\n",
      "  ✔ PTIBS0AM0008 → IBS.LS\n",
      "  ✘ PTINA0AP0008 → NOT FOUND\n",
      "  ✔ PTIPR0AM0000 → IPR.LS\n",
      "  ✔ PTMEN0AE0005 → EGL.LS\n",
      "  ✔ PTMFR0AM0003 → MAR.LS\n",
      "  ✔ PTNBA0AM0006 → NVQ.F\n",
      "  ✔ PTPAD0AM0007 → GLINT.LS\n",
      "  ✔ PTPTC0AM0009 → PHR.LS\n",
      "  ✔ PTTD10AM0000 → TDSA.LS\n",
      "  ✔ PTZON0AM0006 → NOS.LS\n",
      "  ✔ US0008991046 → ADMA\n",
      "  ✔ US00217D1000 → ASTS\n",
      "  ✔ US00402L1070 → ASO\n",
      "  ✔ US0536041041 → AVPT\n",
      "  ✔ US12047B1052 → BMBL\n",
      "  ✔ US12430A3005 → BZFD\n",
      "  ✔ US19260Q1076 → COIN\n",
      "  ✔ US20440W1053 → SID\n",
      "  ✔ US25400Q1058 → DJT\n",
      "  ✔ US36467W1099 → GME\n",
      "  ✔ US4330001060 → HIMS\n",
      "  ✔ US5949603048 → MVIS\n",
      "  ✔ US5949724083 → MSTR\n",
      "  ✔ US5951121038 → MU\n",
      "  ✔ US7707001027 → HOOD\n",
      "  ✔ US79466L3024 → CRM\n",
      "  ✔ US80401C1009 → SATL\n",
      "  ✔ US81684M1045 → SMLR\n",
      "  ✔ US8356993076 → SONYN.MX\n",
      "  ✔ US8740801043 → TAL\n",
      "  ✘ US87968A1043 → NOT FOUND\n",
      "  ✔ US89377M1099 → TMDX\n",
      "  ✔ US91324P1021 → UNH\n",
      "YF.download() has changed argument auto_adjust default to True\n"
     ]
    }
   ],
   "source": [
    "# Get log table\n",
    "final = main(csv_path='../Account.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>ISIN</th>\n",
       "      <th>Qty</th>\n",
       "      <th>Currency</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>2025-04-30</td>\n",
       "      <td>PTBCP0AM0015</td>\n",
       "      <td>-9990</td>\n",
       "      <td>EUR</td>\n",
       "      <td>0.5584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>2025-04-30</td>\n",
       "      <td>PTBCP0AM0015</td>\n",
       "      <td>-24233</td>\n",
       "      <td>EUR</td>\n",
       "      <td>0.5582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2025-04-29</td>\n",
       "      <td>PTBCP0AM0015</td>\n",
       "      <td>34223</td>\n",
       "      <td>EUR</td>\n",
       "      <td>0.5844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>2024-05-28</td>\n",
       "      <td>PTBCP0AM0015</td>\n",
       "      <td>-40000</td>\n",
       "      <td>EUR</td>\n",
       "      <td>0.3600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>2024-05-28</td>\n",
       "      <td>PTBCP0AM0015</td>\n",
       "      <td>-10000</td>\n",
       "      <td>EUR</td>\n",
       "      <td>0.3600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>2024-04-11</td>\n",
       "      <td>PTBCP0AM0015</td>\n",
       "      <td>17500</td>\n",
       "      <td>EUR</td>\n",
       "      <td>0.3128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>2024-04-11</td>\n",
       "      <td>PTBCP0AM0015</td>\n",
       "      <td>17500</td>\n",
       "      <td>EUR</td>\n",
       "      <td>0.3128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>2023-11-22</td>\n",
       "      <td>PTBCP0AM0015</td>\n",
       "      <td>16875</td>\n",
       "      <td>EUR</td>\n",
       "      <td>0.2890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>2023-11-22</td>\n",
       "      <td>PTBCP0AM0015</td>\n",
       "      <td>1875</td>\n",
       "      <td>EUR</td>\n",
       "      <td>0.2890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>2023-07-11</td>\n",
       "      <td>PTBCP0AM0015</td>\n",
       "      <td>-5400</td>\n",
       "      <td>EUR</td>\n",
       "      <td>0.2213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>2023-06-06</td>\n",
       "      <td>PTBCP0AM0015</td>\n",
       "      <td>5400</td>\n",
       "      <td>EUR</td>\n",
       "      <td>0.2090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>2022-06-22</td>\n",
       "      <td>PTBCP0AM0015</td>\n",
       "      <td>22300</td>\n",
       "      <td>EUR</td>\n",
       "      <td>0.1810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>2022-06-22</td>\n",
       "      <td>PTBCP0AM0015</td>\n",
       "      <td>21450</td>\n",
       "      <td>EUR</td>\n",
       "      <td>0.1810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>2022-03-24</td>\n",
       "      <td>PTBCP0AM0015</td>\n",
       "      <td>-50000</td>\n",
       "      <td>EUR</td>\n",
       "      <td>0.1532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>2022-03-17</td>\n",
       "      <td>PTBCP0AM0015</td>\n",
       "      <td>50000</td>\n",
       "      <td>EUR</td>\n",
       "      <td>0.1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>2021-12-15</td>\n",
       "      <td>PTBCP0AM0015</td>\n",
       "      <td>-40000</td>\n",
       "      <td>EUR</td>\n",
       "      <td>0.1373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>2021-11-12</td>\n",
       "      <td>PTBCP0AM0015</td>\n",
       "      <td>39760</td>\n",
       "      <td>EUR</td>\n",
       "      <td>0.1598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>2021-11-12</td>\n",
       "      <td>PTBCP0AM0015</td>\n",
       "      <td>240</td>\n",
       "      <td>EUR</td>\n",
       "      <td>0.1598</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date          ISIN    Qty Currency   Price\n",
       "88  2025-04-30  PTBCP0AM0015  -9990      EUR  0.5584\n",
       "89  2025-04-30  PTBCP0AM0015 -24233      EUR  0.5582\n",
       "98  2025-04-29  PTBCP0AM0015  34223      EUR  0.5844\n",
       "272 2024-05-28  PTBCP0AM0015 -40000      EUR  0.3600\n",
       "273 2024-05-28  PTBCP0AM0015 -10000      EUR  0.3600\n",
       "290 2024-04-11  PTBCP0AM0015  17500      EUR  0.3128\n",
       "291 2024-04-11  PTBCP0AM0015  17500      EUR  0.3128\n",
       "355 2023-11-22  PTBCP0AM0015  16875      EUR  0.2890\n",
       "356 2023-11-22  PTBCP0AM0015   1875      EUR  0.2890\n",
       "382 2023-07-11  PTBCP0AM0015  -5400      EUR  0.2213\n",
       "431 2023-06-06  PTBCP0AM0015   5400      EUR  0.2090\n",
       "473 2022-06-22  PTBCP0AM0015  22300      EUR  0.1810\n",
       "474 2022-06-22  PTBCP0AM0015  21450      EUR  0.1810\n",
       "513 2022-03-24  PTBCP0AM0015 -50000      EUR  0.1532\n",
       "514 2022-03-17  PTBCP0AM0015  50000      EUR  0.1500\n",
       "568 2021-12-15  PTBCP0AM0015 -40000      EUR  0.1373\n",
       "579 2021-11-12  PTBCP0AM0015  39760      EUR  0.1598\n",
       "580 2021-11-12  PTBCP0AM0015    240      EUR  0.1598"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#agg = final.groupby(['Date'], as_index=False).agg({'Position_EUR': 'sum'})\n",
    "#agg.plot(x='Date', y='Position_EUR', kind='line', title='Daily Positions in EUR Notional with Cash')\n",
    "\n",
    "#final[final['Date']=='2025-05-30']\n",
    "\n",
    "trades.query(\"ISIN == 'PTBCP0AM0015'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
